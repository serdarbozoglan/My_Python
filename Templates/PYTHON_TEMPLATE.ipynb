{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "\n",
    "# NLP\n",
    "import contractions\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
    "%load_ext autoreload\n",
    "%aimport helpers, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\"><b>Your emission counts look good!</div></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<div class=\"alert alert-block alert-success\"><b>Your emission counts look good!</div></b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-block alert-success\">Your emission counts look good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "# to get rid of invalid chars we use ISA-8859-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('SMSSpamCollection', header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use .values for y\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAST OPERATION ==> SWIFTER\n",
    "\n",
    "def bikes_proportion(x, max_x):\n",
    "    return x * 1.0 / max_x\n",
    "data['bike_prop'] = data['bikes_available'].swifter.apply(\n",
    "                    bikes_proportion,\n",
    "                    max_x=np.max(data['bikes_available']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "my_additional_stop_word_list = ['no', 'not']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_word_list)\n",
    "\n",
    "CV = CountVectorizer(ngram_range=(1,3), decode_error='ignore', stop_words='english')\n",
    "cv_train = CV.fit_transform(X_train)\n",
    "cv_test = CV.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to perform the pre processing steps on the entire dataset\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# First lemmatize then stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'sample_text.txt'), \"r\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "## data folderin altindaki sample_text file'ini okur    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing a directory of a jupyter notebook\n",
    "\n",
    "import os\n",
    "#os.chdir('/Users/serdar/desktop/datascience/26 ChatBot/Travelers') # New Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:0.24.0\n",
      "seaborn:0.9.0\n"
     ]
    }
   ],
   "source": [
    "# Version check\n",
    "\n",
    "print(f'pandas:{pd.__version__}')\n",
    "print(f'seaborn:{sns.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "## Autosave in every 30 seconds\n",
    "%autosave 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankara Istanbul\n",
      "Ankara ......Istanbul\n",
      "        Ankara ......Istanbul\n",
      "Ankara      Istanbul  Izmir     \n"
     ]
    }
   ],
   "source": [
    "# Print formating\n",
    "a = 'Ankara'\n",
    "b = 'Istanbul' \n",
    "c = 'Izmir'\n",
    "print (a, b)\n",
    "print(f\"{a} {b:.>{14}}\")\n",
    "print(f\"{a:>{14}} {b:.>{14}}\")\n",
    "print('{:<12}{:<10}{:<10}'.format(a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To upgrade all packages at the same time\n",
    "# ! pip freeze — local | grep -v ‘^\\-e’ | cut -d = -f 1 | xargs -n1 pip install -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show rasa_nlu # check the version of a pacakge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sh\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/22/17b22ef5b049f12080f5815c41bf94de3c229217609e469001a8f80c1b3d/sh-1.12.14-py2.py3-none-any.whl\n",
      "Installing collected packages: sh\n",
      "Successfully installed sh-1.12.14\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import GoogleV3\n",
    "\n",
    "place = \"282 Main Street, Lodi, New Jersey\"\n",
    "location = GoogleV3().geocode(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR VISUALIZATION\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\r\n"
     ]
    }
   ],
   "source": [
    "message = 'This is Serdar'\n",
    "!echo message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Serdar\r\n"
     ]
    }
   ],
   "source": [
    "!echo $message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> df['BrandName'].replace(['ABC', 'AB'], 'A')\r\n",
      "0    A\r\n",
      "1    B\r\n",
      "2    A\r\n",
      "3    D\r\n",
      "4    A\r\n"
     ]
    }
   ],
   "source": [
    "# Ask questions and get your answer\n",
    "!howdoi replace in dataframe pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> def print_keyword_args(**kwargs):\r\n",
      "...     # kwargs is a dict of the keyword args passed to the function\r\n",
      "...     for key, value in kwargs.iteritems():\r\n",
      "...         print \"%s = %s\" % (key, value)\r\n",
      "... \r\n",
      ">>> print_keyword_args(first_name=\"John\", last_name=\"Doe\")\r\n",
      "first_name = John\r\n",
      "last_name = Doe\r\n"
     ]
    }
   ],
   "source": [
    "!howdoi **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hello world"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sh\n",
    "\n",
    "sh.pwd()\n",
    "sh.mkdir('Sample Files') # Create a folder\n",
    "sh.touch('Sample_text.txt') # Create a file\n",
    "sh.whoami() # print outs the user\n",
    "sh.echo('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "\n",
    "url = 'https://randomuser.me/api/?results=1'\n",
    "users = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'gender': 'female', 'name': {'title': 'ms', 'first': 'leah', 'last': 'carlson'}, 'location': {'street': '5864 bollinger rd', 'city': 'port macquarie', 'state': 'western australia', 'postcode': 920, 'coordinates': {'latitude': '-86.1325', 'longitude': '6.5569'}, 'timezone': {'offset': '+10:00', 'description': 'Eastern Australia, Guam, Vladivostok'}}, 'email': 'leah.carlson@example.com', 'login': {'uuid': '81df30be-2b8c-49fb-b715-1a7126f44e93', 'username': 'greenbutterfly680', 'password': 'adrian', 'salt': 'UIVL0S7C', 'md5': '7b348ff863dc60482385e6d7406c23d3', 'sha1': '1f220d6f3d1ee4c7eb2551a3b96c576010d72718', 'sha256': '03b33b347559074424c8c918e5dc8ef93f243062e3fc5c65572295a9abec8f52'}, 'dob': {'date': '1969-05-16T20:10:33Z', 'age': 49}, 'registered': {'date': '2003-11-10T02:00:58Z', 'age': 15}, 'phone': '03-9228-5202', 'cell': '0416-475-589', 'id': {'name': 'TFN', 'value': '847384723'}, 'picture': {'large': 'https://randomuser.me/api/portraits/women/17.jpg', 'medium': 'https://randomuser.me/api/portraits/med/women/17.jpg', 'thumbnail': 'https://randomuser.me/api/portraits/thumb/women/17.jpg'}, 'nat': 'AU'}], 'info': {'seed': 'ad4c386751289b8a', 'results': 1, 'page': 1, 'version': '1.2'}}\n"
     ]
    }
   ],
   "source": [
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'info': {'page': 1,\n",
      "          'results': 1,\n",
      "          'seed': 'b32db8e5b914b955',\n",
      "          'version': '1.2'},\n",
      " 'results': [{'cell': '0473-791-896',\n",
      "              'dob': {'age': 68, 'date': '1950-10-01T18:27:18Z'},\n",
      "              'email': 'carolyn.nichols@example.com',\n",
      "              'gender': 'female',\n",
      "              'id': {'name': 'TFN', 'value': '909885589'},\n",
      "              'location': {'city': 'mildura',\n",
      "                           'coordinates': {'latitude': '-84.9902',\n",
      "                                           'longitude': '98.7994'},\n",
      "                           'postcode': 9775,\n",
      "                           'state': 'new south wales',\n",
      "                           'street': '4065 ranchview dr',\n",
      "                           'timezone': {'description': 'Kabul',\n",
      "                                        'offset': '+4:30'}},\n",
      "              'login': {'md5': '59a0db4861c1a3167322ede5d3c08728',\n",
      "                        'password': 'weiner',\n",
      "                        'salt': 'COxCyQyp',\n",
      "                        'sha1': '865efe04cfcbff0cd8a4076a527367f8dc33f8b3',\n",
      "                        'sha256': '94a70f3c66baff19baec6bb51d7c91dc67fbb5b928cb5e0e29c383b4e7e647fb',\n",
      "                        'username': 'angrygorilla563',\n",
      "                        'uuid': '2a7aeb93-b7a6-476a-a4f0-68137f0aedb1'},\n",
      "              'name': {'first': 'carolyn', 'last': 'nichols', 'title': 'mrs'},\n",
      "              'nat': 'AU',\n",
      "              'phone': '09-0688-7149',\n",
      "              'picture': {'large': 'https://randomuser.me/api/portraits/women/43.jpg',\n",
      "                          'medium': 'https://randomuser.me/api/portraits/med/women/43.jpg',\n",
      "                          'thumbnail': 'https://randomuser.me/api/portraits/thumb/women/43.jpg'},\n",
      "              'registered': {'age': 12, 'date': '2006-02-09T12:39:04Z'}}]}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 13:14:23) \r\n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin\r\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n",
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%xmode Plain\n",
    "%pdb on\n",
    "\n",
    "# Other modes of xmode Verbose , Context\n",
    "# %pdb debugger runs after exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %timeit line-magic and %%timeit cell-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1:\n",
      "import sys \n",
      "!{sys.executable} -m pip install memory_profiler\n",
      "   2: %history -n 1-4\n"
     ]
    }
   ],
   "source": [
    "%history -n 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1) # Shows column without truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING FILE WITH SKIPPING AND ONLY READ 200 ROWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('reviews_data.txt.gz', skiprows=10000, nrows=200, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR SEABORN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context('notebook') # maybe poster\n",
    "# sns.set_context('poster', font_scale=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatui = [\"#9b59b6\", \"#3498db\"] # guzel renkler\n",
    "g = sns.PairGrid(df, vars=['age', 'test', 'bid', 'win', 'conversion'],\n",
    "                 hue='gender', palette=flatui)\n",
    "g.map(plt.scatter, alpha=0.8)\n",
    "g.add_legend();\n",
    "\n",
    "sns.set(rc={'figure.figsize':(15,6)})\n",
    "sns.countplot(x='bid', hue='gender', data=df, palette=flatui) #palette='Set_1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISSING VALUES TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns with missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING A FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('whoops.txt', 'r') as mynewfile:\n",
    "    myvariable = mynewfile.readlines()\n",
    "    \n",
    "## This context manager automatically close the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING WITH CHUNKSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url='http://bit.ly/2cLzoxH''\n",
    "# use chunk size 500\n",
    "c_size = 500\n",
    "for gm_chunk in pd.read_csv(csv_url,chunksize=c_size):\n",
    "    print(gm_chunk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM STR TO DATETIME\n",
    "\n",
    "a = datetime.datetime.strptime(df['Date'][0], \"%b %d %Y\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/serdarbozoglan/Desktop/DataScience'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CURRENT DIRECTORY\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FROM PDF TO TXT\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from cStringIO import StringIO\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = file(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "\n",
    "lone=convert_pdf_to_txt('doc_3Trademark_Transfer_Agreement.pdf')\n",
    "\n",
    "\n",
    "f=open('xxx.txt','w')\n",
    "f.write(lone)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "with open('xxx.txt') as f:\n",
    "    clean_cont = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced CSV loading example\n",
    "data = pd.read_csv(\n",
    "        \"data/files/complex_data_example.tsv\",      # relative python path to subdirectory\n",
    "        sep='\\t'           # Tab-separated value file.\n",
    "        quotechar=\"'\",        # single quote allowed as quote character\n",
    "        dtype={\"salary\": int},             # Parse the salary column as an integer \n",
    "        usecols=['name', 'birth_date', 'salary'].   # Only load the three columns specified.\n",
    "        parse_dates=['birth_date'],     # Intepret the birth_date column as a date\n",
    "        skiprows=10,         # Skip the first 10 rows of the file\n",
    "        na_values=['.', '??']       # Take any '.' or '??' values as NA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y_test)\n",
    "np.sum(y_pred == y_test)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size ve xticks/yticks boyutu\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "plt.tick_params(labelsize=15)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] =(8,6)\n",
    "params = {'xticks.font': 16,}\n",
    "flatui = [\"#9b59b6\", \"#3498db\"]\n",
    "\n",
    "sns.countplot(x ='y', data=df,palette=flatui)\n",
    "plt.xticks(fontsize=17), plt.yticks(fontsize=17)\n",
    "plt.xlabel('Target', fontsize=17), plt.ylabel('Count', fontsize=17)\n",
    "plt.legend(loc='upper right', borderpad=-2)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bank.csv', 'r') as file: ## Reads file at once\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice # Partial reading from the dataset\n",
    "with open(\"bank-full.csv\") as myfile:\n",
    "    head = list(islice(myfile, 5))\n",
    "print (head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(dataset):\n",
    "    for var in categorical:\n",
    "        categorical_list = \"var\"+\"_\"+var \n",
    "        categorical_list = pd.get_dummies(dataset[var], prefix = var,)\n",
    "        temp_df = dataset.join(categorical_list)\n",
    "        dataset = temp_df\n",
    "    \n",
    "    temp_df_cat_cols = dataset.columns.values.tolist()\n",
    "    kept_columns = [col for col in temp_df_cat_cols if col not in categorical]\n",
    "    dataset = dataset[kept_columns]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(x,y, 'r')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(y,x, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "axes[0].plot(x,y, 'r');\n",
    "axes[0].set_title('FIRST PLOT')\n",
    "\n",
    "axes[1].plot(y,x, 'g')\n",
    "axes[1].set_title('SECOND PLOT')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qgrid\n",
    "qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "qgrid_widget\n",
    "df1 = qgrid_widget.get_changed_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
